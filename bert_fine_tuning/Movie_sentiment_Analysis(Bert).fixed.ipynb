{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhushanmandava/LLM_fine_tuning/blob/main/Movie_sentiment_Analysis(Bert).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2cz39sYM_7"
      },
      "source": [
        "# Fine tuning LLm for  Movie Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDN8gjr_YgTw",
        "outputId": "fd3041ea-06b9-42d6-bc62-db4067d0e1d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NCBYO3MqYM_7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset,DatasetDict,Dataset\n",
        "from transformers import (\n",
        "AutoTokenizer,\n",
        "AutoConfig,\n",
        "AutoModelForSequenceClassification,\n",
        "DataCollatorWithPadding,\n",
        "TrainingArguments,\n",
        "Trainer\n",
        ")\n",
        "\n",
        "from peft import PeftModel , PeftConfig,get_peft_model,LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "cedf99b86ebd4487b9f724ecdc7ae551",
            "8c9449b6a5154a6781880001663f5b69",
            "87bdaf62405c40798db28ab38ba62f03",
            "b027174eca4345fcb1fe4723b0bb6249",
            "bb5f4f1a5a214a7b9196dbe05e03b235",
            "f493e16449eb43e291127e95a81cc1bc",
            "5b80544c22d84768aa936607723c936d",
            "9eb18e70a0ae441f8252cb47643409d2",
            "94ae7311e29c42d49cd1a87a90b8548f",
            "c06f7671e4ac47feb7bd28ecfaf8db39",
            "bf8a3789d4364240ba2df8158937e5b5",
            "a51f270ace384a9887102031c24cb252",
            "1d8b61e172364093985cc2a9535cda54",
            "dc7182ae374847f5a6c7e8cb1a36fde4",
            "52fc461f74dc4136a108f45705164132",
            "6bd932687de24fe1b92bff5b69a7df02",
            "edc7299ff9cd477ab332afb41a6953c1",
            "0535dd21369e4e9480d8fbdad787bc79",
            "a9433943fa804e939c60f11526c84e26",
            "563d209fd05a4ceebce5774bbaf17eb6",
            "47a00334969a4fd8a68afa8d77c5b7a9",
            "46140939bfcd4ec4802a67deca5d1999",
            "999a4bc5e4dd47c0b7f1d21a99e416f2",
            "0364866e71bd49ac8960e1e53969c142",
            "0a6d3c338e164b3ba341ca2e5d97ee23",
            "87a47437510244ec92bf8d1d30fb80fb",
            "f4e08847433e4a0eaea7caf81b93b9eb",
            "6e48a8f860a440169f095663927fbc31",
            "d81588ffd3554727bf1c65767b659829",
            "e3cb2545670b43c4a55db14bea2d6a4f",
            "d814cdbac510474b84480de84203f385",
            "072dd2f7ded546959fa99484a721c9f2",
            "e6c10de12174418c9e53a21c4c9219fb",
            "aa1c6a37263249d8976095525384f1d5",
            "b2191cfec6e34f06ada33bd835d9315c",
            "7eed4a4c34e04c009689c7d2b06e73a3",
            "19a3057ef8ca4b25a3c024480f1a97b8",
            "2c8ad84766e24ad29039c27e13e46d25",
            "bd1bd5f8255344389fee6bcef5d2d9ea",
            "2f3d86dea3ad477d91430601e49f5f99",
            "a1d553bcad534e69933558bb2911a088",
            "08d47bed6a7d4982802f5e1fc2deb6c0",
            "f7c11573506b4c29b33bbc88d33c5d44",
            "edc6043dad71413e8c6e2274e7ddbe56",
            "7d4a41a7290a452db8a2ae22664021b2",
            "f2bbb4c436414657b767d4a12009d509",
            "d090daccae264123a20b982fe60ae97f",
            "d129e8dca9ae4b4cbc653ee4b1ed5b20",
            "40da163ac3cc41cebbb60538a8d3d5d3",
            "ccb8cbadc8b54f29a40b65cb47406256",
            "72dca20c5660489e90644e5557a8613e",
            "ce7bfb213c0e42cb80686a9efff99d87",
            "80036a1641cb4e4488c6e7c4f94a2d15",
            "0934ec040ce5459baaffecf75282472d",
            "ae41169b96ef4954b3351380bb486487"
          ]
        },
        "id": "z70TdPLjYM_8",
        "outputId": "a4a7ee64-2337-49f5-a7c9-123266dc4c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cedf99b86ebd4487b9f724ecdc7ae551"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(‚Ä¶)-00000-of-00001-5a744bf76a1d84b2.parquet:   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a51f270ace384a9887102031c24cb252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(‚Ä¶)-00000-of-00001-a3a52fabb70c739f.parquet:   0%|          | 0.00/853k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999a4bc5e4dd47c0b7f1d21a99e416f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1c6a37263249d8976095525384f1d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d4a41a7290a452db8a2ae22664021b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset = load_dataset('shawhin/imdb-truncated')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8kujBArYM_8",
        "outputId": "2e87b019-2780-4fff-a225-776c47c8b666"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])\n",
        "#so we can say labels are equally distributed and we are giving enough chances for model to learn positive and negative sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "17fefd9746304358b56b1af3a001c256",
            "966d0fa5953c45708393227b9071dd9d",
            "d236cb6186fa42a1b2eb249d255a39ad",
            "4366db38c86b488aa013ceb929a55a76",
            "a2a27755fec04e149dcb62efa31e9ad4",
            "9309218f569b4780ae8af85f021f4902",
            "f737eb51b91c4f6bbc8c39bc0ea9f2c7",
            "c6020d30837a4a21939abc306712b1a2",
            "cb191978fadb4765a941dcc9eda5d5cf",
            "3fec7200c23f4bdbbf34a4ffe062a4d0",
            "cb7b8f77614e44c7811dbebc244236a7",
            "fc0e57b7efda492d9c3ce4327dc21dca",
            "7687d2e539534331884a9b857db2f233",
            "d7bffc8e1a2e475eb46b203a8d38c5c3",
            "658f1169a0ba4f908d37b869b64c8f8d",
            "33722256cbe941579bd3b9890849f4f1",
            "98faf9829de54450834409963a7a2ce1",
            "6943c307e2854669a8901ba52571666e",
            "039aa9bd88da45059833abca0043e380",
            "db0e79e5d16648f1aa4d0f172bbedbdf",
            "f1b83395bddb4c859e07874483a23909",
            "9bd2b4d728fa4565a6714151a8e4cb03"
          ]
        },
        "id": "cIWATo-2YM_8",
        "outputId": "1d3f3428-9e6d-404f-f293-18beeb69eba9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17fefd9746304358b56b1af3a001c256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc0e57b7efda492d9c3ce4327dc21dca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#starting with or base model\n",
        "model_checkpoint = 'distilbert-base-uncased'\n",
        "\n",
        "\n",
        "#defining our label maps\n",
        "id2label = {\n",
        "    0:'Negative',\n",
        "    1:'Positive'\n",
        "}\n",
        "label2id = {\"Negative\":0, \"Positive\":1}\n",
        "# using AutoModelForSeuentialclassification  changing our model heads\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNVl2ITgYM_8",
        "outputId": "ac6b7510-8c32-4ff8-ae3c-b5e6f2ad2ab9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RMg8LqZYM_8",
        "outputId": "1a97cdea-1be8-4218-b133-4634fb6d338c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsXFdH4IYM_8"
      },
      "source": [
        "You can seee clearly that it only uses The Encoder part of the transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc1G1QEHYM_9"
      },
      "source": [
        "## Preprocessing The data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "997e93d2a6e14de0b88234c0d78a43bb",
            "09b17664c90e436fb9bb143285a08860",
            "0762886082cd403b9d49383b4e079ef8",
            "b2d8e4586c504a1385145ffae54f74d4",
            "341d89b528164423a3560e4ef467015c",
            "3611a16bb0a54bafb1386b79a42a601d",
            "dc6cdeec77054adc8ad99bcbad22deda",
            "1dae789a31434680bd9daf341d5dca51",
            "8496f07892c64e43b9ba0763c4765fb5",
            "d2cbfeb6f81f49bbac0a07041d7f5e53",
            "4615f3e6e303452e8604e51624d3bd2f",
            "0373356234fe448dac8962283c7fb6b5",
            "2434fd993a9d42c2b357ccd337583d38",
            "feb731cb922640aa9196ab24c88ccef0",
            "0e3fdea69b994b1bb15500f186db5122",
            "bbf0b83c519c4ddb9efa98b063472c56",
            "53c1b21667f8492b9d4fd08ae4826d01",
            "3eec4cebbb8e44dd975b4be12952aca5",
            "1463e74587474352b83fc68bce6c83d2",
            "d79a29ea2cc64592806a2e162102170f",
            "b3dd2cd1e2ea4a818ac1b10f5ff41a86",
            "2dc23b617eae434d8e767d4e8714cf90",
            "d89ef7aa549143779bb8cb2ded24a465",
            "940508f0cfc3488bb225c19e6b5387a9",
            "653ab2185d624bd3b4d0599eb70afc80",
            "9a36bfa1c11a480fbb5d0b849cabd2de",
            "6554b02fb5a14a93bfe4bb5af0bc19b4",
            "a2d217e11a5f4c2d9a4ac77597920a61",
            "4bedc2df1eac4b3499a31b7f326eef19",
            "0fb1d27d3b894924a2b7cc279164e12e",
            "544994590b144c9fb3a9a806ce92a923",
            "384ea7960d8643a892805251a8a26355",
            "a64a2fd1ebee4de1ab0468da437001be"
          ]
        },
        "id": "rB4uGTDIYM_9",
        "outputId": "93bedfc8-97f1-4e1c-ae95-405af27db09e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "997e93d2a6e14de0b88234c0d78a43bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0373356234fe448dac8962283c7fb6b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d89ef7aa549143779bb8cb2ded24a465"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,add_prefix_space=True)# getting our model specific tokenizer\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token':'<pad>'})#if the tokinzer dosent have pad ytoken we adding our own\n",
        "    model.resize_token_embeddings(len(tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jMFBgBZ_YM_9"
      },
      "outputs": [],
      "source": [
        "def tokinizer_function(examples):\n",
        "    text= examples[\"text\"]\n",
        "    tokenizer.truncation_side =\"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "6172ec67704b4befb78df465f6804da8",
            "ec1abb3f8c15413db2e163cb38095ba9",
            "ca954b18f8064a669be04b959e80eddf",
            "5a1fb2e8f01e4159aec9df827890fb93",
            "3a1426ad4c6346ca8fbacb76d5490e92",
            "345a94fb7f5b4eeeaab3e5f3d80e34a8",
            "4494e52252db453aaf0070cb21a1743c",
            "16c758575c974adcb0873f706f36e166",
            "0098fd0963d24e238eb945fdbd73bda0",
            "982f77ad0e2a4b57b28891cf3188c604",
            "4cbdcab8aaa34b7d960e18f9b18112d5",
            "b965ab49f44447ce8b9bb38ce67b8eaa",
            "2fcd9c93bc3e43f18f86eaf5b305167e",
            "cbbdfe8f578246afad13cd70638c823e",
            "308f10c5536d45f29df893e8de35dcc1",
            "b565ff948d9444278e94ffb8d0fbf38c",
            "b25aa13b8631453887e07b11908bcd5d",
            "984cac885dc7473299a647b37a9ff4c6",
            "f82853e47ff5486fb063baec99842293",
            "64336d0efb444390bc3d12d46a3ece16",
            "785e2ac4cb944c82aaff8bad145b97fb",
            "39f56f3f2aa345bf950b76476c08923f"
          ]
        },
        "id": "qB8O0g-fYM_9",
        "outputId": "fe416874-d96f-47b1-828f-e83e80f10247"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6172ec67704b4befb78df465f6804da8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b965ab49f44447ce8b9bb38ce67b8eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#mapping our function\n",
        "tokenized_dataset = dataset.map(tokinizer_function,batched = True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FxS7onDYM_9"
      },
      "source": [
        "### now our data is preprocessed bassed on our model requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CciNV1b0YM_9"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6hXPtRSpYM_9"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "#our evaluation metric would be accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RKkV4N_BYM_9"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    # If it's a binary classification task\n",
        "    if predictions.ndim == 1 or predictions.shape[1] == 1:\n",
        "        pred = np.round(predictions)\n",
        "    else:\n",
        "        # Multi-class classification\n",
        "        pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = (pred == labels).mean()\n",
        "    return {\"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJGpTSPdYM_9",
        "outputId": "36921601-88be-48d8-9147-ff8960ca4de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "untrained predictions\n",
            "**************************************************\n",
            "it was a good movie - Positive\n",
            "good god,thats the worst film - Positive\n",
            "better than first film - Positive\n",
            "not worth the time - Positive\n"
          ]
        }
      ],
      "source": [
        "text_list =[\"it was a good movie\",\"good god,thats the worst film\",\"better than first film\",\"not worth the time\"]\n",
        "print(\"untrained predictions\")\n",
        "print(\"*\"*50)\n",
        "for text in text_list:\n",
        "    inputs=tokenizer.encode(text,return_tensors=\"pt\")\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    logits = model(inputs).logits\n",
        "    predictions =torch.argmax(logits)\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fA6g4WWYM_9"
      },
      "source": [
        "#### see our model is way off so we train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3AvGn7XYM_-",
        "outputId": "fbe79e88-d625-4573-d1ed-5109e33b95df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "distilbert\n",
            "distilbert.embeddings\n",
            "distilbert.embeddings.word_embeddings\n",
            "distilbert.embeddings.position_embeddings\n",
            "distilbert.embeddings.LayerNorm\n",
            "distilbert.embeddings.dropout\n",
            "distilbert.transformer\n",
            "distilbert.transformer.layer\n",
            "distilbert.transformer.layer.0\n",
            "distilbert.transformer.layer.0.attention\n",
            "distilbert.transformer.layer.0.attention.dropout\n",
            "distilbert.transformer.layer.0.attention.q_lin\n",
            "distilbert.transformer.layer.0.attention.k_lin\n",
            "distilbert.transformer.layer.0.attention.v_lin\n",
            "distilbert.transformer.layer.0.attention.out_lin\n",
            "distilbert.transformer.layer.0.sa_layer_norm\n",
            "distilbert.transformer.layer.0.ffn\n",
            "distilbert.transformer.layer.0.ffn.dropout\n",
            "distilbert.transformer.layer.0.ffn.lin1\n",
            "distilbert.transformer.layer.0.ffn.lin2\n",
            "distilbert.transformer.layer.0.ffn.activation\n",
            "distilbert.transformer.layer.0.output_layer_norm\n",
            "distilbert.transformer.layer.1\n",
            "distilbert.transformer.layer.1.attention\n",
            "distilbert.transformer.layer.1.attention.dropout\n",
            "distilbert.transformer.layer.1.attention.q_lin\n",
            "distilbert.transformer.layer.1.attention.k_lin\n",
            "distilbert.transformer.layer.1.attention.v_lin\n",
            "distilbert.transformer.layer.1.attention.out_lin\n",
            "distilbert.transformer.layer.1.sa_layer_norm\n",
            "distilbert.transformer.layer.1.ffn\n",
            "distilbert.transformer.layer.1.ffn.dropout\n",
            "distilbert.transformer.layer.1.ffn.lin1\n",
            "distilbert.transformer.layer.1.ffn.lin2\n",
            "distilbert.transformer.layer.1.ffn.activation\n",
            "distilbert.transformer.layer.1.output_layer_norm\n",
            "distilbert.transformer.layer.2\n",
            "distilbert.transformer.layer.2.attention\n",
            "distilbert.transformer.layer.2.attention.dropout\n",
            "distilbert.transformer.layer.2.attention.q_lin\n",
            "distilbert.transformer.layer.2.attention.k_lin\n",
            "distilbert.transformer.layer.2.attention.v_lin\n",
            "distilbert.transformer.layer.2.attention.out_lin\n",
            "distilbert.transformer.layer.2.sa_layer_norm\n",
            "distilbert.transformer.layer.2.ffn\n",
            "distilbert.transformer.layer.2.ffn.dropout\n",
            "distilbert.transformer.layer.2.ffn.lin1\n",
            "distilbert.transformer.layer.2.ffn.lin2\n",
            "distilbert.transformer.layer.2.ffn.activation\n",
            "distilbert.transformer.layer.2.output_layer_norm\n",
            "distilbert.transformer.layer.3\n",
            "distilbert.transformer.layer.3.attention\n",
            "distilbert.transformer.layer.3.attention.dropout\n",
            "distilbert.transformer.layer.3.attention.q_lin\n",
            "distilbert.transformer.layer.3.attention.k_lin\n",
            "distilbert.transformer.layer.3.attention.v_lin\n",
            "distilbert.transformer.layer.3.attention.out_lin\n",
            "distilbert.transformer.layer.3.sa_layer_norm\n",
            "distilbert.transformer.layer.3.ffn\n",
            "distilbert.transformer.layer.3.ffn.dropout\n",
            "distilbert.transformer.layer.3.ffn.lin1\n",
            "distilbert.transformer.layer.3.ffn.lin2\n",
            "distilbert.transformer.layer.3.ffn.activation\n",
            "distilbert.transformer.layer.3.output_layer_norm\n",
            "distilbert.transformer.layer.4\n",
            "distilbert.transformer.layer.4.attention\n",
            "distilbert.transformer.layer.4.attention.dropout\n",
            "distilbert.transformer.layer.4.attention.q_lin\n",
            "distilbert.transformer.layer.4.attention.k_lin\n",
            "distilbert.transformer.layer.4.attention.v_lin\n",
            "distilbert.transformer.layer.4.attention.out_lin\n",
            "distilbert.transformer.layer.4.sa_layer_norm\n",
            "distilbert.transformer.layer.4.ffn\n",
            "distilbert.transformer.layer.4.ffn.dropout\n",
            "distilbert.transformer.layer.4.ffn.lin1\n",
            "distilbert.transformer.layer.4.ffn.lin2\n",
            "distilbert.transformer.layer.4.ffn.activation\n",
            "distilbert.transformer.layer.4.output_layer_norm\n",
            "distilbert.transformer.layer.5\n",
            "distilbert.transformer.layer.5.attention\n",
            "distilbert.transformer.layer.5.attention.dropout\n",
            "distilbert.transformer.layer.5.attention.q_lin\n",
            "distilbert.transformer.layer.5.attention.k_lin\n",
            "distilbert.transformer.layer.5.attention.v_lin\n",
            "distilbert.transformer.layer.5.attention.out_lin\n",
            "distilbert.transformer.layer.5.sa_layer_norm\n",
            "distilbert.transformer.layer.5.ffn\n",
            "distilbert.transformer.layer.5.ffn.dropout\n",
            "distilbert.transformer.layer.5.ffn.lin1\n",
            "distilbert.transformer.layer.5.ffn.lin2\n",
            "distilbert.transformer.layer.5.ffn.activation\n",
            "distilbert.transformer.layer.5.output_layer_norm\n",
            "pre_classifier\n",
            "classifier\n",
            "dropout\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0DBbHld1YM_-"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type =\"SEQ_CLS\",\n",
        "    r=4,\n",
        "    lora_alpha =32,\n",
        "    lora_dropout=0.1,\n",
        "target_modules=['q_lin'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rH6MCz-YM_-",
        "outputId": "3784d1cf-4dc7-478f-d959-1652f4f31963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=4, target_modules={'q_lin'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, eva_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "peft_config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "n27Y0orYZXT5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjlaMdSLYM_-",
        "outputId": "4c7e9b81-8d23-4762-fd7e-78705b830c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 67584004\n",
            "Trainable parameters: 628994\n",
            "Non-trainable parameters: 66955010\n"
          ]
        }
      ],
      "source": [
        "# Check the number of trainable parameters in the model\n",
        "def print_trainable_parameters(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"Trainable parameters: {trainable_params}\")\n",
        "    print(f\"Non-trainable parameters: {total_params - trainable_params}\")\n",
        "\n",
        "# Call the function for your model\n",
        "print_trainable_parameters(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mnlMmufCYM_-"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-5\n",
        "batch_size = 2\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q553auJdYM_-",
        "outputId": "d4d02e44-1cf9-42cf-986e-c76f42685327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "Aro4o3bqYM_-",
        "outputId": "b6208cba-230b-4e01-d9c5-9291f5ffaf05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-e8e4c1055773>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 06:33, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.684100</td>\n",
              "      <td>0.670383</td>\n",
              "      <td>0.663000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.660500</td>\n",
              "      <td>0.631024</td>\n",
              "      <td>0.837000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.606600</td>\n",
              "      <td>0.541647</td>\n",
              "      <td>0.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.493500</td>\n",
              "      <td>0.395706</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.376700</td>\n",
              "      <td>0.310003</td>\n",
              "      <td>0.878000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.329000</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>0.878000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.309600</td>\n",
              "      <td>0.290163</td>\n",
              "      <td>0.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.313900</td>\n",
              "      <td>0.294083</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.329100</td>\n",
              "      <td>0.300639</td>\n",
              "      <td>0.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.324400</td>\n",
              "      <td>0.303185</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5000, training_loss=0.4427349304199219, metrics={'train_runtime': 393.8293, 'train_samples_per_second': 25.392, 'train_steps_per_second': 12.696, 'total_flos': 920634052343472.0, 'train_loss': 0.4427349304199219, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hdM0bdMYM_-",
        "outputId": "abe02eb1-273f-46db-942d-3d6959d87e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model predictions:\n",
            "--------------------------\n",
            "it was a good movie - Positive\n",
            "good god,thats the worst film - Negative\n",
            "better than first film - Positive\n",
            "not worth the time - Negative\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "for text in text_list:\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "    logits = model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (german2english)",
      "language": "python",
      "name": "german2english"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
